# -*- coding: utf-8 -*-
"""onion_densetnet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1czb7XfVRGFQ9Gc3AFXw6dLCwi5xsF3Lb
"""

# STEP 1: Upload service account key
from google.colab import files
uploaded = files.upload()

# STEP 2: Set environment and download from GCS
import os
json_filename = list(uploaded.keys())[0]
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = json_filename
print(f"Using service account: {json_filename}")

# STEP 3: Download Onion dataset from GCS
GCS_URI = "gs://onion11"
!mkdir -p OnionData
!gsutil -m cp -r {GCS_URI}/* OnionData/

# STEP 4: Prepare dataset
import shutil
import random

base_dir = 'OnionData'
class_id_to_name = {}
classes_txt_path = os.path.join(base_dir, 'classes.txt')

if os.path.exists(classes_txt_path):
    with open(classes_txt_path, 'r') as f:
        for i, line in enumerate(f):
            class_id_to_name[str(i)] = line.strip()

jpgs = {os.path.splitext(f)[0]: f for f in os.listdir(base_dir) if f.endswith('.jpg')}
txts = {os.path.splitext(f)[0]: f for f in os.listdir(base_dir) if f.endswith('.txt')}
paired = [base for base in jpgs if base in txts]

class_to_images = {}
for base in paired:
    with open(os.path.join(base_dir, txts[base]), 'r') as f:
        line = f.readline().strip()
        if line:
            class_id = line.split()[0]
            label = class_id_to_name.get(class_id, f"class_{class_id}")
            class_to_images.setdefault(label, []).append(jpgs[base])

for split in ['train', 'val', 'test']:
    shutil.rmtree(split, ignore_errors=True)
    for label in class_to_images:
        os.makedirs(os.path.join(split, label), exist_ok=True)

for label, images in class_to_images.items():
    random.shuffle(images)
    n = len(images)
    train_n, val_n = int(0.8*n), int(0.1*n)
    for img in images[:train_n]:
        shutil.copy(os.path.join(base_dir, img), os.path.join('train', label, img))
    for img in images[train_n:train_n+val_n]:
        shutil.copy(os.path.join(base_dir, img), os.path.join('val', label, img))
    for img in images[train_n+val_n:]:
        shutil.copy(os.path.join(base_dir, img), os.path.join('test', label, img))

# STEP 5: Data loading
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

IMG_SIZE = 224
BATCH_SIZE = 32

train_gen = ImageDataGenerator(rescale=1./255)
val_gen = ImageDataGenerator(rescale=1./255)
test_gen = ImageDataGenerator(rescale=1./255)

train_loader = train_gen.flow_from_directory('train', target_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE, class_mode='categorical')
val_loader = val_gen.flow_from_directory('val', target_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE, class_mode='categorical')
test_loader = test_gen.flow_from_directory('test', target_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE, class_mode='categorical')

print("Detected classes:", train_loader.class_indices)

# STEP 6: DenseNet121 model
from tensorflow.keras.applications import DenseNet121
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.models import Model

base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(512, activation='relu')(x)
x = Dropout(0.5)(x)
predictions = Dense(len(train_loader.class_indices), activation='softmax')(x)
model = Model(inputs=base_model.input, outputs=predictions)

for layer in base_model.layers:
    layer.trainable = False

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

# STEP 7: Train the model
import time
EPOCHS = 10
start_time = time.time()

history = model.fit(train_loader, validation_data=val_loader, epochs=EPOCHS)
training_time = time.time() - start_time

# STEP 8: Evaluate model
import matplotlib.pyplot as plt

test_loss, test_accuracy = model.evaluate(test_loader)

plt.plot(history.history["accuracy"], label="Train Accuracy")
plt.plot(history.history["val_accuracy"], label="Validation Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.title("Accuracy over Epochs")
plt.grid(True)
plt.show()

# STEP 9: Classification report, Confusion matrix, AUC
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, auc
from sklearn.preprocessing import label_binarize
import seaborn as sns

y_pred = model.predict(test_loader)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = test_loader.classes
class_labels = list(test_loader.class_indices.keys())

print("\nüìä Classification Report:")
print(classification_report(y_true, y_pred_classes, target_names=class_labels))

cm = confusion_matrix(y_true, y_pred_classes)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix")
plt.show()

# AUC-ROC
y_true_bin = label_binarize(y_true, classes=range(len(class_labels)))

plt.figure(figsize=(12, 8))
for i, label in enumerate(class_labels):
    fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_pred[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, lw=2, label=f"{label} (AUC = {roc_auc:.2f})")

plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("AUC-ROC Curve (One-vs-Rest)")
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

# STEP 10: Final metrics summary
model_size_MB = sum([np.prod(v.shape) for v in model.trainable_variables]) * 4 / (1024 ** 2)

print(f"\n‚úÖ Training Accuracy: {history.history['accuracy'][-1] * 100:.2f}%")
print(f"‚úÖ Validation Accuracy: {history.history['val_accuracy'][-1] * 100:.2f}%")
print(f"‚úÖ Test Accuracy: {test_accuracy * 100:.2f}%")
print(f"‚è±Ô∏è Training Time: {training_time:.2f} seconds")
print(f"üì¶ Model Size: {model_size_MB:.2f} MB")
print(f"üßÆ Macro-average AUC: {roc_auc_score(y_true_bin, y_pred, average='macro'):.4f}")
print(f"üßÆ Weighted-average AUC: {roc_auc_score(y_true_bin, y_pred, average='weighted'):.4f}")
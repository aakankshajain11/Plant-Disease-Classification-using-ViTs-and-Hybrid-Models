# -*- coding: utf-8 -*-
"""healthy_diffusion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g-hZYFs-YRW7DvRUbCnbuVlsYkY6y10r
"""

# STEP 1: Install required libraries
!pip uninstall -y diffusers -q
!pip install diffusers==0.29.0 -q
!pip install transformers accelerate torch torchvision matplotlib scikit-image xformers -q

# STEP 2: Upload and Extract ZIP File
from google.colab import files
import zipfile, os

uploaded = files.upload()  # Upload healthy.zip here
zip_filename = next(iter(uploaded))
output_dir = "./healthy_dataset"
os.makedirs(output_dir, exist_ok=True)

with zipfile.ZipFile(zip_filename, 'r') as zip_ref:
    zip_ref.extractall(output_dir)

print(f"‚úÖ Extracted {zip_filename} to {output_dir}")

# STEP 3: Dataset Preparation
import glob
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
import random

# Custom Dataset Class
class HealthyDiffusionDataset(Dataset):
    def __init__(self, root_dir, transform=None, num_samples=None):
        valid_exts = ('.jpg', '.jpeg', '.png', '.bmp')
        self.image_paths = [f for f in glob.glob(f"{root_dir}/**/*", recursive=True) if f.lower().endswith(valid_exts)]
        if num_samples:
            self.image_paths = random.sample(self.image_paths, min(num_samples, len(self.image_paths)))
        self.transform = transform
        print(f"‚úÖ Found {len(self.image_paths)} images with valid extensions.")

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        image = Image.open(img_path).convert("RGB")
        if self.transform:
            image = self.transform(image)
        return image

# STEP 4: Load Dataset
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])
])

dataset = HealthyDiffusionDataset(output_dir, transform=transform)
print(f"‚úÖ Loaded {len(dataset)} healthy images")

# STEP 5: Show Sample Images
def show_images(images, title="", n=10):
    if len(images) == 0:
        print("‚ö†Ô∏è No images to display.")
        return
    plt.figure(figsize=(20, 4))
    for i in range(min(n, len(images))):
        img = images[i].permute(1, 2, 0).numpy()
        img = (img - img.min()) / (img.max() - img.min())
        plt.subplot(1, n, i + 1)
        plt.imshow(img)
        plt.axis("off")
    plt.suptitle(title)
    plt.show()

real_images = [dataset[i] for i in range(min(10, len(dataset)))]
show_images(real_images, "‚úÖ Sample Real Healthy Images")

# STEP 3: Diffusion Model Setup
from diffusers import UNet2DModel, DDPMScheduler, DDPMPipeline

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
torch.backends.cudnn.benchmark = True
torch.cuda.empty_cache()

model = UNet2DModel(
    sample_size=224,
    in_channels=3,
    out_channels=3,
    layers_per_block=2,
    block_out_channels=(64, 128, 256, 512),
    down_block_types=("DownBlock2D", "DownBlock2D", "AttnDownBlock2D", "DownBlock2D"),
    up_block_types=("UpBlock2D", "AttnUpBlock2D", "UpBlock2D", "UpBlock2D"),
    attention_head_dim=8
).to(device)

model.enable_xformers_memory_efficient_attention()

noise_scheduler = DDPMScheduler(num_train_timesteps=500, beta_schedule="linear")
optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-6)

# STEP 4: Train the Diffusion Model
from tqdm.auto import tqdm

dataloader = DataLoader(dataset, batch_size=4, shuffle=True, pin_memory=True)
num_epochs = 10
losses = []
accumulation_steps = 4

for epoch in range(num_epochs):
    model.train()
    epoch_loss = 0
    optimizer.zero_grad()

    for step, batch in enumerate(tqdm(dataloader, desc=f"Epoch {epoch+1}/{num_epochs}")):
        batch = batch.to(device)

        with torch.cuda.amp.autocast():
            noise = torch.randn_like(batch)
            timesteps = torch.randint(0, noise_scheduler.num_train_timesteps, (batch.shape[0],)).long().to(device)
            noisy_images = noise_scheduler.add_noise(batch, noise, timesteps)
            noise_pred = model(noisy_images, timesteps).sample
            loss = torch.nn.functional.mse_loss(noise_pred, noise) / accumulation_steps

        loss.backward()

        if (step + 1) % accumulation_steps == 0:
            optimizer.step()
            optimizer.zero_grad()
            torch.cuda.empty_cache()

        epoch_loss += loss.item() * accumulation_steps

    avg_loss = epoch_loss / len(dataloader)
    losses.append(avg_loss)
    print(f"‚úÖ Epoch {epoch+1} - Loss: {avg_loss:.4f}")

# Plot Loss
plt.plot(losses)
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Training Loss Curve")
plt.grid(True)
plt.show()

# STEP 6: Generate 50 Synthetic Healthy Images
import gc
model.eval()
torch.cuda.empty_cache()
gc.collect()

from diffusers import DDPMPipeline

pipeline = DDPMPipeline(unet=model, scheduler=noise_scheduler).to(device)

num_images = 50  # ‚úÖ Only generate 50 images
gen_batch_size = 2
synthetic_images = []

from tqdm.auto import tqdm
print("üîÑ Generating 50 synthetic healthy images...")

for i in tqdm(range(0, num_images, gen_batch_size)):
    with torch.cuda.amp.autocast():
        images = pipeline(
            batch_size=gen_batch_size,
            num_inference_steps=500,  # ‚úÖ Match training steps
            generator=torch.manual_seed(42 + i),
            output_type="pil"
        ).images
    synthetic_images.extend(images)
    torch.cuda.empty_cache()

print(f"‚úÖ Generated {len(synthetic_images)} synthetic healthy images")

# STEP 6: Display Synthetic Images
def show_synthetic(images, title="Synthetic Healthy Samples"):
    fig, axes = plt.subplots(1, 10, figsize=(20, 4))
    for i, img in enumerate(images[:10]):
        axes[i].imshow(img)
        axes[i].axis("off")
    plt.suptitle(title)
    plt.show()

show_synthetic(synthetic_images)

# STEP 7: Save Synthetic Images
os.makedirs("SyntheticHealthy", exist_ok=True)
from torchvision.utils import save_image
for i, img in enumerate(synthetic_images):
    img.save(f"SyntheticHealthy/synthetic_healthy_{i:03d}.jpg")

print("‚úÖ All synthetic healthy images saved in 'SyntheticHealthy' folder.")
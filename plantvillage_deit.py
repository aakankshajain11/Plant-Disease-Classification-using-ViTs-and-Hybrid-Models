# -*- coding: utf-8 -*-
"""plantvillage_DeiT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZFaW46-9qMqW9QFxK5I0ApOJRD0jqHHp
"""

# STEP 1: Authenticate and download dataset from Kaggle
from google.colab import files
uploaded = files.upload()  # Upload kaggle.json

import os, zipfile
json_filename = list(uploaded.keys())[0]
os.environ['KAGGLE_CONFIG_DIR'] = "/content"
!mkdir -p ~/.kaggle
!cp {json_filename} ~/.kaggle/kaggle.json
!chmod 600 ~/.kaggle/kaggle.json

# Download dataset
!kaggle datasets download -d emmarex/plantdisease
!unzip -q plantdisease.zip -d PlantVillageRaw

# STEP 2: Organize data into train/val/test folders (fixed for case-sensitive extensions)
import shutil, random
from pathlib import Path

data_dir = Path("PlantVillageRaw/PlantVillage")
output_dirs = {'train': Path("train"), 'val': Path("val"), 'test': Path("test")}
for split in output_dirs.values():
    shutil.rmtree(split, ignore_errors=True)

all_classes = [f.name for f in data_dir.iterdir() if f.is_dir()]
for split in output_dirs:
    for cls in all_classes:
        os.makedirs(output_dirs[split] / cls, exist_ok=True)

def get_all_images(folder):
    return [p for p in folder.iterdir() if p.suffix.lower() in ['.jpg', '.jpeg', '.png']]

for cls in all_classes:
    class_path = data_dir / cls
    images = get_all_images(class_path)
    random.shuffle(images)
    n = len(images)
    t, v = int(0.8 * n), int(0.1 * n)
    splits = {'train': images[:t], 'val': images[t:t+v], 'test': images[t+v:]}
    for split in splits:
        for img in splits[split]:
            shutil.copy(img, output_dirs[split] / cls / img.name)

# STEP 3: DeiT Implementation
!pip install -q transformers timm torchmetrics seaborn

import time
import torch
import torch.nn as nn
from torchvision.datasets import ImageFolder
from torchvision import transforms
from torch.utils.data import DataLoader
from transformers import DeiTForImageClassification
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, auc
from sklearn.preprocessing import label_binarize
import numpy as np

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

train_ds = ImageFolder("train", transform=transform)
val_ds = ImageFolder("val", transform=transform)
test_ds = ImageFolder("test", transform=transform)

train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)
val_loader = DataLoader(val_ds, batch_size=32)
test_loader = DataLoader(test_ds, batch_size=32)

# Model
model = DeiTForImageClassification.from_pretrained(
    "facebook/deit-base-distilled-patch16-224",
    num_labels=len(train_ds.classes)
)
model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.AdamW(model.parameters(), lr=3e-5)
epochs = 10

train_accs, val_accs, train_losses, val_losses = [], [], [], []
start_time = time.time()

for epoch in range(epochs):
    model.train()
    correct, total, train_loss = 0, 0, 0
    for imgs, lbls in train_loader:
        imgs, lbls = imgs.to(device), lbls.to(device)
        optimizer.zero_grad()
        outputs = model(imgs).logits
        loss = criterion(outputs, lbls)
        loss.backward()
        optimizer.step()
        train_loss += loss.item() * imgs.size(0)
        correct += (outputs.argmax(1) == lbls).sum().item()
        total += lbls.size(0)
    train_losses.append(train_loss / total)
    train_accs.append(correct / total)

    model.eval()
    correct, total, val_loss = 0, 0, 0
    with torch.no_grad():
        for imgs, lbls in val_loader:
            imgs, lbls = imgs.to(device), lbls.to(device)
            outputs = model(imgs).logits
            val_loss += criterion(outputs, lbls).item() * imgs.size(0)
            correct += (outputs.argmax(1) == lbls).sum().item()
            total += lbls.size(0)
    val_losses.append(val_loss / total)
    val_accs.append(correct / total)

    print(f"Epoch {epoch+1}: Train Acc={train_accs[-1]:.4f}, Val Acc={val_accs[-1]:.4f}")

training_time = time.time() - start_time

# STEP 4: Final Evaluation
model.eval()
y_true, y_pred_probs = [], []
with torch.no_grad():
    for imgs, lbls in test_loader:
        imgs = imgs.to(device)
        outputs = model(imgs).logits
        y_pred_probs.append(outputs.cpu())
        y_true.append(lbls)

y_pred_probs = torch.cat(y_pred_probs).softmax(dim=1).numpy()
y_pred = np.argmax(y_pred_probs, axis=1)
y_true = torch.cat(y_true).numpy()
class_labels = train_ds.classes

# Plot Loss and Accuracy
plt.plot(train_accs, label="Train Accuracy")
plt.plot(val_accs, label="Val Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.title("Accuracy Curve")
plt.legend()
plt.grid(True)
plt.show()

# Classification Report
print("\nüìä Classification Report:\n", classification_report(y_true, y_pred, target_names=class_labels))

# Confusion Matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_labels, yticklabels=class_labels, cmap="Blues")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix")
plt.show()

# AUC-ROC
y_true_bin = label_binarize(y_true, classes=range(len(class_labels)))
plt.figure(figsize=(12, 8))
for i in range(len(class_labels)):
    fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_pred_probs[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, lw=2, label=f"{class_labels[i]} (AUC = {roc_auc:.2f})")
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel("FPR")
plt.ylabel("TPR")
plt.title("ROC Curve (OvR)")
plt.legend()
plt.grid(True)
plt.show()

# Macro & Weighted AUC
print(f"üßÆ Macro AUC: {roc_auc_score(y_true_bin, y_pred_probs, average='macro'):.4f}")
print(f"üßÆ Weighted AUC: {roc_auc_score(y_true_bin, y_pred_probs, average='weighted'):.4f}")

# STEP 5: Summary
model_size = sum(p.numel() for p in model.parameters() if p.requires_grad) * 4 / (1024 ** 2)
print(f"\n‚úÖ Final Train Accuracy: {train_accs[-1]*100:.2f}%")
print(f"‚úÖ Final Validation Accuracy: {val_accs[-1]*100:.2f}%")
print(f"‚úÖ Test Accuracy: {(y_pred == y_true).mean()*100:.2f}%")
print(f"‚è±Ô∏è Total Training Time: {training_time:.2f} seconds")
print(f"üì¶ Model Size: {model_size:.2f} MB")
# -*- coding: utf-8 -*-
"""bacterial_diffusion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14rW59q7PbuVlC1fQoeMveNuI1X8ySKLI
"""

# STEP 1: Install required libraries
!pip uninstall -y diffusers -q
!pip install diffusers==0.29.0 -q
!pip install transformers accelerate torch torchvision matplotlib scikit-image xformers -q

# STEP 2: Upload and Extract ZIP File
from google.colab import files
import zipfile, os

uploaded = files.upload()  # Upload bacterial.zip here
zip_filename = next(iter(uploaded))
output_dir = "./bacterial_dataset"
os.makedirs(output_dir, exist_ok=True)

with zipfile.ZipFile(zip_filename, 'r') as zip_ref:
    zip_ref.extractall(output_dir)

print(f"‚úÖ Extracted {zip_filename} to {output_dir}")

# STEP 3: Dataset Preparation
import glob
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
import random

class BacterialDiffusionDataset(Dataset):
    def __init__(self, root_dir, transform=None, num_samples=None):
        valid_exts = ('.jpg', '.jpeg', '.png', '.bmp')
        self.image_paths = [f for f in glob.glob(f"{root_dir}/**/*", recursive=True) if f.lower().endswith(valid_exts)]
        if num_samples:
            self.image_paths = random.sample(self.image_paths, min(num_samples, len(self.image_paths)))
        self.transform = transform
        print(f"‚úÖ Found {len(self.image_paths)} images with valid extensions.")

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        image = Image.open(img_path).convert("RGB")
        if self.transform:
            image = self.transform(image)
        return image

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])
])

dataset = BacterialDiffusionDataset(output_dir, transform=transform)
print(f"‚úÖ Loaded {len(dataset)} bacterial images")

# STEP 4: Show Sample Images
def show_images(images, title="", n=10):
    if len(images) == 0:
        print("‚ö†Ô∏è No images to display.")
        return
    plt.figure(figsize=(20, 4))
    for i in range(min(n, len(images))):
        img = images[i].permute(1, 2, 0).numpy()
        img = (img - img.min()) / (img.max() - img.min())
        plt.subplot(1, n, i + 1)
        plt.imshow(img)
        plt.axis("off")
    plt.suptitle(title)
    plt.show()

real_images = [dataset[i] for i in range(min(10, len(dataset)))]
show_images(real_images, "‚úÖ Sample Real Bacterial Images")

# STEP 5: Diffusion Model Setup
from diffusers import UNet2DModel, DDPMScheduler, DDPMPipeline

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
torch.backends.cudnn.benchmark = True
torch.cuda.empty_cache()

model = UNet2DModel(
    sample_size=224,
    in_channels=3,
    out_channels=3,
    layers_per_block=2,
    block_out_channels=(64, 128, 256, 512),
    down_block_types=("DownBlock2D", "DownBlock2D", "AttnDownBlock2D", "DownBlock2D"),
    up_block_types=("UpBlock2D", "AttnUpBlock2D", "UpBlock2D", "UpBlock2D"),
    attention_head_dim=8
).to(device)

model.enable_xformers_memory_efficient_attention()

noise_scheduler = DDPMScheduler(num_train_timesteps=500, beta_schedule="linear")
optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-6)

# STEP 6: Training Loop
from tqdm.auto import tqdm

dataloader = DataLoader(dataset, batch_size=4, shuffle=True, pin_memory=True)
num_epochs = 10
losses = []
accumulation_steps = 4

for epoch in range(num_epochs):
    model.train()
    epoch_loss = 0
    optimizer.zero_grad()

    for step, batch in enumerate(tqdm(dataloader, desc=f"Epoch {epoch+1}/{num_epochs}")):
        batch = batch.to(device)

        with torch.cuda.amp.autocast():
            noise = torch.randn_like(batch)
            timesteps = torch.randint(0, noise_scheduler.num_train_timesteps, (batch.shape[0],)).long().to(device)
            noisy_images = noise_scheduler.add_noise(batch, noise, timesteps)
            noise_pred = model(noisy_images, timesteps).sample
            loss = torch.nn.functional.mse_loss(noise_pred, noise) / accumulation_steps

        loss.backward()

        if (step + 1) % accumulation_steps == 0:
            optimizer.step()
            optimizer.zero_grad()
            torch.cuda.empty_cache()

        epoch_loss += loss.item() * accumulation_steps

    avg_loss = epoch_loss / len(dataloader)
    losses.append(avg_loss)
    print(f"‚úÖ Epoch {epoch+1} - Loss: {avg_loss:.4f}")

# STEP 7: Plot Loss Curve
plt.plot(losses)
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Training Loss Curve on Bacterial Dataset")
plt.grid(True)
plt.show()

# STEP 8: Generate Synthetic Images
import gc
model.eval()
torch.cuda.empty_cache()
gc.collect()

pipeline = DDPMPipeline(unet=model, scheduler=noise_scheduler).to(device)

num_images = 50
gen_batch_size = 2
synthetic_images = []

print("üîÑ Generating 50 synthetic bacterial images...")

for i in tqdm(range(0, num_images, gen_batch_size)):
    with torch.cuda.amp.autocast():
        images = pipeline(
            batch_size=gen_batch_size,
            num_inference_steps=500,
            generator=torch.manual_seed(42 + i),
            output_type="pil"
        ).images
    synthetic_images.extend(images)
    torch.cuda.empty_cache()

print(f"‚úÖ Generated {len(synthetic_images)} synthetic bacterial images")

# STEP 9: Show & Save Synthetic Images
def show_synthetic(images, title="Synthetic Bacterial Samples"):
    fig, axes = plt.subplots(1, 10, figsize=(20, 4))
    for i, img in enumerate(images[:10]):
        axes[i].imshow(img)
        axes[i].axis("off")
    plt.suptitle(title)
    plt.show()

show_synthetic(synthetic_images)

os.makedirs("SyntheticBacterial", exist_ok=True)
for i, img in enumerate(synthetic_images):
    img.save(f"SyntheticBacterial/synthetic_bacterial_{i:03d}.jpg")

print("‚úÖ All synthetic bacterial images saved in 'SyntheticBacterial' folder.")
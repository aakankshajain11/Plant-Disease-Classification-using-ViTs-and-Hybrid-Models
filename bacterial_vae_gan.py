# -*- coding: utf-8 -*-
"""bacterial_vae-gan.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eqF0LiNphcYCqBmU8H_Uvlaqs3dc8tem
"""

# Step 1: Install and Import Required Libraries
!pip install -q torchvision matplotlib

import os
import time
import zipfile
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from tqdm import tqdm

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, utils

from google.colab import files
uploaded = files.upload()  # Upload 'bacterial.zip'
!unzip -o "*.zip" -d ./bacterial_dataset/

# Step 2: Image Preprocessing
transform = transforms.Compose([
    transforms.Resize((64, 64)),
    transforms.ToTensor()
])

# Step 3: Custom Dataset
class BacterialDataset(Dataset):
    def __init__(self, image_dir, transform=None):
        self.transform = transform
        self.image_paths = []
        valid_exts = ('.jpg', '.jpeg', '.png', '.bmp')
        for root, _, files in os.walk(image_dir):
            for file in files:
                if file.lower().endswith(valid_exts):
                    self.image_paths.append(os.path.join(root, file))

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        image = Image.open(self.image_paths[idx]).convert("RGB")
        if self.transform:
            image = self.transform(image)
        return image

# Step 4: Load Dataset
image_dir = './bacterial_dataset/'
dataset = BacterialDataset(image_dir, transform)
print(f"✅ Total bacterial images found: {len(dataset)}")

dataloader = DataLoader(dataset, batch_size=32, shuffle=True)

# Show 10 sample images
sample_batch = next(iter(dataloader))
plt.figure(figsize=(10, 5))
for i in range(10):
    img = sample_batch[i].permute(1, 2, 0).numpy()
    plt.subplot(2, 5, i+1)
    plt.imshow(img)
    plt.axis('off')
plt.suptitle("✅ 10 Sample Preprocessed Bacterial Images")
plt.show()

# Step 5: Define Models
latent_dim = 128

class Encoder(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(3, 64, 4, 2, 1), nn.ReLU(),
            nn.Conv2d(64, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),
            nn.Conv2d(128, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU()
        )
        self.fc_mu = nn.Linear(256*8*8, latent_dim)
        self.fc_logvar = nn.Linear(256*8*8, latent_dim)

    def forward(self, x):
        x = self.conv(x).view(x.size(0), -1)
        mu = self.fc_mu(x)
        logvar = self.fc_logvar(x)
        return mu, logvar

class Decoder(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc = nn.Linear(latent_dim, 256*8*8)
        self.deconv = nn.Sequential(
            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),
            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.ReLU(),
            nn.ConvTranspose2d(64, 3, 4, 2, 1), nn.Tanh()
        )

    def forward(self, z):
        x = self.fc(z).view(z.size(0), 256, 8, 8)
        return self.deconv(x)

class Discriminator(nn.Module):
    def __init__(self):
        super().__init__()
        self.main = nn.Sequential(
            nn.Conv2d(3, 64, 4, 2, 1), nn.LeakyReLU(0.2),
            nn.Conv2d(64, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.LeakyReLU(0.2),
            nn.Conv2d(128, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.LeakyReLU(0.2),
            nn.Flatten(),
            nn.Linear(256*8*8, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        return self.main(x)

# Step 6: Initialize Models
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
encoder = Encoder().to(device)
decoder = Decoder().to(device)
discriminator = Discriminator().to(device)

# Optimizers
optimizer_G = optim.Adam(decoder.parameters(), lr=0.0001)
optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0001)
optimizer_E = optim.Adam(encoder.parameters(), lr=0.0001)

# Losses
bce_loss = nn.BCELoss()
mse_loss = nn.MSELoss()

# Reparameterization
def reparameterize(mu, logvar):
    std = torch.exp(0.5 * logvar)
    return mu + std * torch.randn_like(std)

# Step 7: Training Loop
def train(num_epochs=120):
    start = time.time()
    for epoch in range(num_epochs):
        for batch in dataloader:
            real_imgs = batch.to(device)
            batch_size = real_imgs.size(0)
            valid = torch.ones(batch_size, 1, device=device)
            fake = torch.zeros(batch_size, 1, device=device)

            # === Train Encoder + Decoder ===
            optimizer_G.zero_grad()
            optimizer_E.zero_grad()

            mu, logvar = encoder(real_imgs)
            z = reparameterize(mu, logvar)
            recon_imgs = decoder(z)
            pred_fake = discriminator(recon_imgs)

            kld = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())
            recon_loss = mse_loss(recon_imgs, real_imgs)
            adv_loss = bce_loss(pred_fake, valid)
            g_loss = recon_loss + kld + adv_loss

            g_loss.backward()
            optimizer_G.step()
            optimizer_E.step()

            # === Train Discriminator ===
            optimizer_D.zero_grad()
            pred_real = discriminator(real_imgs)
            loss_real = bce_loss(pred_real, valid)

            pred_fake = discriminator(recon_imgs.detach())
            loss_fake = bce_loss(pred_fake, fake)

            d_loss = 0.5 * (loss_real + loss_fake)
            d_loss.backward()
            optimizer_D.step()

        print(f"Epoch {epoch+1}/{num_epochs} | D Loss: {d_loss.item():.4f} | G Loss: {g_loss.item():.4f}")

        # Show generated images
        with torch.no_grad():
            z = torch.randn(10, latent_dim).to(device)
            gen_imgs = decoder(z)
            grid = utils.make_grid(gen_imgs.cpu(), nrow=5, normalize=True)
            plt.figure(figsize=(8, 4))
            plt.imshow(grid.permute(1, 2, 0))
            plt.title(f"Epoch {epoch+1} Generated")
            plt.axis('off')
            plt.show()

    end = time.time()
    print(f"\n✅ Training completed in {end - start:.2f} seconds.")

train(num_epochs=50)

# Step 8: Save 50 Synthetic Images
os.makedirs("synthetic_outputs", exist_ok=True)
decoder.eval()
with torch.no_grad():
    z = torch.randn(50, latent_dim).to(device)
    synthetic_images = decoder(z).cpu()
    for idx, img in enumerate(synthetic_images):
        utils.save_image(img, f"synthetic_outputs/synthetic_{idx+1}.png", normalize=True)
print("✅ 50 synthetic images saved in 'synthetic_outputs' folder.")